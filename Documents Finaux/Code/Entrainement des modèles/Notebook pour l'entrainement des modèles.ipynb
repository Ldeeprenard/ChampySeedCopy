{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cdc94a7",
   "metadata": {},
   "source": [
    "# Notebook pour l'entrainement des modèles \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6b9e2c",
   "metadata": {},
   "source": [
    "## Importation des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a7e4c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os  \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras import Model \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import random\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73ce4cf",
   "metadata": {},
   "source": [
    "### On choisit le batch_size que l'on souhaite utililser\n",
    "Nous avons constater que pour avoir un temps d'execution minimal, le batch_size dépendait principalement des machines sur lequel on entreprend l'entrainement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "badbbe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b785dad1",
   "metadata": {},
   "source": [
    "## Importation du csv \n",
    "Le csv \"Afternotfungi2.csv\" contient tous les chemins des photos présentes dans le dossier esperons\n",
    "Si vous voulez faire fonctionner le notebook, il vous faudra avoir télécharger les images et indiquer le dossier dans base_dir\n",
    "Ensuite la colonne path de df contiendra vos chemins personalisés jusqu'a vos photos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbfd68a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baugn\\anaconda3\\envs\\gputest\\lib\\site-packages\\numpy\\lib\\arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "\n",
    "# Chargement du fichier\n",
    "df = pd.read_csv (\"Champyseed.csv\",index_col=0)\n",
    "\n",
    "#Création d'une nouvelle variable contenant l'arborescence sur le HDD des fichiers images\n",
    "df[\"path\"] = '\\\\'+df[\"order\"]+'\\\\'+df[\"family\"]+'\\\\'+df[\"genus\"]+'\\\\'+df[\"species\"]+'\\\\'+'im'+df.notreid.astype('str')+\".jpg\"\n",
    "\n",
    "# On ajoute le chemin où se trouve l'arborescence précédente (peut varier selon les personnes)\n",
    "base_dir = r'C:\\Users\\baugn\\Mush\\esperons'\n",
    "df[\"path\"] = base_dir+df[\"path\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966fd724",
   "metadata": {},
   "source": [
    "## Choix des données pour l'entrainement\n",
    "Il vous faut choisir le nombre de classe, le type de classe et le nombre de photos par classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6767d2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_classe=64\n",
    "types=\"genus\"     #décommenter la ligne que vous souhaitez\n",
    "#type=\"species\"\n",
    "nombre_de_photos_par_classe=8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2de4834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#La cellule suivante va creer un dataframe data qui va contenir les lignes du dataframe df avec les caractéristiques que vous avez choisies\n",
    "#précédemment: Dans l'exemple pré-enregistré data contiendra 8000 lignes pour chaque genus. Le choix des genus est choisi parmis tous les genus\n",
    "#triés par ordre décroissant de photos disponibles. \n",
    "#Si jamais il n'y a pas assez de photos dans un genus , alors la fonction prendra tout ce qu'elle peut au sein de ce genus\n",
    "# Dans l'exemple toutes les classes ont plus de 8000 photos et elles ont donc toutes 8000 photos.\n",
    "\n",
    "def creation_de_ma_data(nombre_classe):\n",
    "    liste_classe=df[types].value_counts().index.tolist()\n",
    "    if nombre_classe>len(df[types].unique()):\n",
    "        print(\"Pas assez de classes dans le dataset actuel (\",len(df[types].unique()),\")\")\n",
    "        return\n",
    "    \n",
    "    c=pd.DataFrame()\n",
    "    for i in range(0,nombre_classe):\n",
    "        if len(df[df[types]==liste_classe[i]])>nombre_de_photos_par_classe:\n",
    "            cplus=df[df[types]==liste_classe[i]].sample(nombre_de_photos_par_classe)\n",
    "        else:\n",
    "            cplus=df[df[types]==liste_classe[i]].sample(len(df[df[types]==liste_classe[i]]))\n",
    "        c=pd.concat([c,cplus])\n",
    "    return c\n",
    "data=creation_de_ma_data(nombre_classe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3678c27d",
   "metadata": {},
   "source": [
    "# Différenciation des deux méthodes utilisées -- Méthode avec ImageDataGenerator\n",
    "Nous avons utilisé deux types d'entrainement. Le premier utilise le module ImageDataGenrator qui permet de se simplifier beaucoup la vie en terme de code. ImageFataGenerator nous permet de créer un genérateur d'image qui peut se \"nourir\" d'un dataframe en lui indiquanr les colonnes du chemin des photos, et celui de la target.\n",
    "ImageDataGenerator permet aussi de faire de la data augmentation. Ici nous n'utilisons que 3 fonctions d'augmentation.\n",
    "rotation_range\n",
    "zoom_range\n",
    "brightness_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b0fa44",
   "metadata": {},
   "source": [
    "## Découpage en train test de notre dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dbc98df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_train, data_test = train_test_split(data, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb13b0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "\n",
    "# Création de deux générateurs d'images différent, un pour la partie Train et un pour la partie Test\n",
    "train_datagen = ImageDataGenerator(preprocessing_function = preprocess_input,\n",
    "                                   rotation_range = 180,\n",
    "                                   #width_shift_range = 0.2,\n",
    "                                   #height_shift_range = 0.2,\n",
    "                                   #shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   brightness_range = [0.9,1.1])\n",
    "                                   #horizontal_flip = False)\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "450c622e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 409600 validated image filenames belonging to 64 classes.\n",
      "Found 102400 validated image filenames belonging to 64 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#On indique avec la méthode flow_from_dataframe les différentes caractéristiques utiles de notre dataframe\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=data_train,\n",
    "                                                    directory = \"\",\n",
    "                                                    x_col = \"path\",\n",
    "                                                    y_col = types,\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    class_mode = 'sparse', #\"raw\", #\"'binary'\n",
    "                                                    target_size = (224, 224))\n",
    "\n",
    "# Validation avec les images de test sur le HDD\n",
    "validation_generator = test_datagen.flow_from_dataframe(dataframe=data_test,\n",
    "                                                        directory=\"\",\n",
    "                                                        x_col = \"path\",\n",
    "                                                        y_col = types,\n",
    "                                                        batch_size = batch_size,\n",
    "                                                        class_mode = 'sparse',\n",
    "                                                        target_size = (224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55ffcfe",
   "metadata": {},
   "source": [
    "## Définition des callbacks\n",
    "Les callbacks sont des outils qui permettent d'effectuer des contrôles au cours de l'entrainement\n",
    "Nous en utilisons 3:\n",
    "- checkpoint : permet d'enregistrer le modèle, le modèle est sauvegardé à chaque fin d'epoch quand la valeur \"monitor\" s'est améliorée\n",
    "- early : permet d'arreter le modèle quand la valeur \"monitor\" ne s'améliore pas pendant le nombre d'epoch \"patience\"\n",
    "- reduce_lr : permet de réduire(par la valeur \"factor\") le learning rate quand la valeur monitor ne s'est pas améliorée pendant le nombre d'epoch \"patience\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "093fb497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"res50imdatagen.h5\", \n",
    "                             monitor='val_acc', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             save_weights_only=False, \n",
    "                             mode='auto', \n",
    "                             save_freq=\"epoch\")\n",
    "\n",
    "early = EarlyStopping(monitor='val_acc', \n",
    "                      min_delta=0, \n",
    "                      patience=6, \n",
    "                      verbose=1, \n",
    "                      mode='auto')\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                              factor=0.2,\n",
    "                              patience=3,\n",
    "                              cooldown=1,\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92293c40",
   "metadata": {},
   "source": [
    "## Importation du modèle pré-entrainé (Transfert Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "737d8ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bea69f",
   "metadata": {},
   "source": [
    "## Création de la couche de classification, des métriques utilisées et  compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c446ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet')\n",
    "\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(units = 1024, activation = 'relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(units = 512, activation = 'relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(units = nombre_classe, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer = \"adam\", #optimizer = tf.keras.optimizers.SGD(learning_rate=0.0001), \n",
    "                   loss = 'sparse_categorical_crossentropy', #loss = 'binary_crossentropy', \n",
    "                   metrics = ['acc',tf.keras.metrics.SparseTopKCategoricalAccuracy(\n",
    "    k=5, name='top_5'),tf.keras.metrics.SparseTopKCategoricalAccuracy(\n",
    "    k=3, name='top_3')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3ec0fa",
   "metadata": {},
   "source": [
    "## Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33e3a5f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "800/800 [==============================] - 4282s 5s/step - loss: 2.3558 - acc: 0.3706 - top_5: 0.6844 - top_3: 0.5835 - val_loss: 1.8056 - val_acc: 0.4998 - val_top_5: 0.8003 - val_top_3: 0.7123\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.49980, saving model to res50imdatagen.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baugn\\anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "800/800 [==============================] - 5163s 6s/step - loss: 2.0031 - acc: 0.4527 - top_5: 0.7624 - top_3: 0.6701 - val_loss: 1.7277 - val_acc: 0.5201 - val_top_5: 0.8161 - val_top_3: 0.7323\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.49980 to 0.52009, saving model to res50imdatagen.h5\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 5032s 6s/step - loss: 1.9050 - acc: 0.4758 - top_5: 0.7819 - top_3: 0.6925 - val_loss: 1.6490 - val_acc: 0.5401 - val_top_5: 0.8265 - val_top_3: 0.7470\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.52009 to 0.54011, saving model to res50imdatagen.h5\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 4603s 6s/step - loss: 1.8503 - acc: 0.4889 - top_5: 0.7915 - top_3: 0.7041 - val_loss: 1.6126 - val_acc: 0.5494 - val_top_5: 0.8338 - val_top_3: 0.7561\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.54011 to 0.54937, saving model to res50imdatagen.h5\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 4343s 5s/step - loss: 1.8085 - acc: 0.5004 - top_5: 0.7998 - top_3: 0.7135 - val_loss: 1.5921 - val_acc: 0.5546 - val_top_5: 0.8360 - val_top_3: 0.7593\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.54937 to 0.55455, saving model to res50imdatagen.h5\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 4203s 5s/step - loss: 1.7811 - acc: 0.5073 - top_5: 0.8039 - top_3: 0.7197 - val_loss: 1.5765 - val_acc: 0.5584 - val_top_5: 0.8392 - val_top_3: 0.7630\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.55455 to 0.55838, saving model to res50imdatagen.h5\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 4070s 5s/step - loss: 1.7583 - acc: 0.5124 - top_5: 0.8079 - top_3: 0.7242 - val_loss: 1.5551 - val_acc: 0.5631 - val_top_5: 0.8428 - val_top_3: 0.7682\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.55838 to 0.56309, saving model to res50imdatagen.h5\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 4073s 5s/step - loss: 1.7397 - acc: 0.5175 - top_5: 0.8116 - top_3: 0.7292 - val_loss: 1.5503 - val_acc: 0.5656 - val_top_5: 0.8425 - val_top_3: 0.7687\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.56309 to 0.56557, saving model to res50imdatagen.h5\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 4058s 5s/step - loss: 1.7231 - acc: 0.5215 - top_5: 0.8147 - top_3: 0.7322 - val_loss: 1.5521 - val_acc: 0.5653 - val_top_5: 0.8422 - val_top_3: 0.7664\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.56557\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 4058s 5s/step - loss: 1.7090 - acc: 0.5245 - top_5: 0.8162 - top_3: 0.7352 - val_loss: 1.5247 - val_acc: 0.5713 - val_top_5: 0.8461 - val_top_3: 0.7721\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.56557 to 0.57130, saving model to res50imdatagen.h5\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 4073s 5s/step - loss: 1.6918 - acc: 0.5290 - top_5: 0.8195 - top_3: 0.7385 - val_loss: 1.5434 - val_acc: 0.5695 - val_top_5: 0.8431 - val_top_3: 0.7704\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.57130\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 4890s 6s/step - loss: 1.6818 - acc: 0.5323 - top_5: 0.8225 - top_3: 0.7419 - val_loss: 1.5117 - val_acc: 0.5769 - val_top_5: 0.8482 - val_top_3: 0.7751\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.57130 to 0.57693, saving model to res50imdatagen.h5\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 4747s 6s/step - loss: 1.6729 - acc: 0.5336 - top_5: 0.8228 - top_3: 0.7429 - val_loss: 1.5040 - val_acc: 0.5798 - val_top_5: 0.8491 - val_top_3: 0.7772\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.57693 to 0.57979, saving model to res50imdatagen.h5\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 5174s 6s/step - loss: 1.6615 - acc: 0.5369 - top_5: 0.8247 - top_3: 0.7454 - val_loss: 1.5183 - val_acc: 0.5760 - val_top_5: 0.8466 - val_top_3: 0.7735\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.57979\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 4805s 6s/step - loss: 1.6538 - acc: 0.5382 - top_5: 0.8267 - top_3: 0.7465 - val_loss: 1.5052 - val_acc: 0.5776 - val_top_5: 0.8499 - val_top_3: 0.7779\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.57979\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 4121s 5s/step - loss: 1.6450 - acc: 0.5402 - top_5: 0.8276 - top_3: 0.7488 - val_loss: 1.4886 - val_acc: 0.5828 - val_top_5: 0.8525 - val_top_3: 0.7806\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.57979 to 0.58284, saving model to res50imdatagen.h5\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 4482s 6s/step - loss: 1.6376 - acc: 0.5433 - top_5: 0.8286 - top_3: 0.7499 - val_loss: 1.4962 - val_acc: 0.5814 - val_top_5: 0.8511 - val_top_3: 0.7797\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.58284\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 4335s 5s/step - loss: 1.6308 - acc: 0.5438 - top_5: 0.8302 - top_3: 0.7516 - val_loss: 1.4967 - val_acc: 0.5809 - val_top_5: 0.8497 - val_top_3: 0.7781\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.58284\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 4047s 5s/step - loss: 1.6236 - acc: 0.5469 - top_5: 0.8304 - top_3: 0.7531 - val_loss: 1.4793 - val_acc: 0.5861 - val_top_5: 0.8533 - val_top_3: 0.7831\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.58284 to 0.58613, saving model to res50imdatagen.h5\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 4216s 5s/step - loss: 1.6184 - acc: 0.5472 - top_5: 0.8321 - top_3: 0.7550 - val_loss: 1.4916 - val_acc: 0.5828 - val_top_5: 0.8505 - val_top_3: 0.7812\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.58613\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 5293s 7s/step - loss: 1.6127 - acc: 0.5493 - top_5: 0.8329 - top_3: 0.7556 - val_loss: 1.4881 - val_acc: 0.5821 - val_top_5: 0.8521 - val_top_3: 0.7819\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.58613\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 4265s 5s/step - loss: 1.6059 - acc: 0.5513 - top_5: 0.8343 - top_3: 0.7574 - val_loss: 1.4816 - val_acc: 0.5856 - val_top_5: 0.8524 - val_top_3: 0.7825\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.58613\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 4991s 6s/step - loss: 1.5066 - acc: 0.5751 - top_5: 0.8507 - top_3: 0.7774 - val_loss: 1.4154 - val_acc: 0.6025 - val_top_5: 0.8629 - val_top_3: 0.7954\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.58613 to 0.60251, saving model to res50imdatagen.h5\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 4170s 5s/step - loss: 1.4801 - acc: 0.5818 - top_5: 0.8542 - top_3: 0.7826 - val_loss: 1.4119 - val_acc: 0.6021 - val_top_5: 0.8636 - val_top_3: 0.7955\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.60251\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 3980s 5s/step - loss: 1.4687 - acc: 0.5835 - top_5: 0.8565 - top_3: 0.7847 - val_loss: 1.3985 - val_acc: 0.6065 - val_top_5: 0.8654 - val_top_3: 0.7982\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.60251 to 0.60651, saving model to res50imdatagen.h5\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 3981s 5s/step - loss: 1.4619 - acc: 0.5860 - top_5: 0.8572 - top_3: 0.7859 - val_loss: 1.4077 - val_acc: 0.6040 - val_top_5: 0.8644 - val_top_3: 0.7954\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.60651\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 3994s 5s/step - loss: 1.4531 - acc: 0.5886 - top_5: 0.8586 - top_3: 0.7881 - val_loss: 1.3974 - val_acc: 0.6070 - val_top_5: 0.8657 - val_top_3: 0.7983\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.60651 to 0.60701, saving model to res50imdatagen.h5\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 3985s 5s/step - loss: 1.4477 - acc: 0.5892 - top_5: 0.8600 - top_3: 0.7893 - val_loss: 1.3933 - val_acc: 0.6070 - val_top_5: 0.8660 - val_top_3: 0.7986\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.60701 to 0.60702, saving model to res50imdatagen.h5\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 3994s 5s/step - loss: 1.4427 - acc: 0.5897 - top_5: 0.8605 - top_3: 0.7898 - val_loss: 1.3869 - val_acc: 0.6096 - val_top_5: 0.8671 - val_top_3: 0.8002\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.60702 to 0.60965, saving model to res50imdatagen.h5\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 4220s 5s/step - loss: 1.4404 - acc: 0.5909 - top_5: 0.8610 - top_3: 0.7906 - val_loss: 1.3843 - val_acc: 0.6100 - val_top_5: 0.8676 - val_top_3: 0.8004\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.60965 to 0.61004, saving model to res50imdatagen.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "800/800 [==============================] - 4535s 6s/step - loss: 1.4363 - acc: 0.5908 - top_5: 0.8619 - top_3: 0.7916 - val_loss: 1.3836 - val_acc: 0.6099 - val_top_5: 0.8678 - val_top_3: 0.8008\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.61004\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 4754s 6s/step - loss: 1.4317 - acc: 0.5928 - top_5: 0.8625 - top_3: 0.7923 - val_loss: 1.3827 - val_acc: 0.6101 - val_top_5: 0.8681 - val_top_3: 0.8008\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.61004 to 0.61009, saving model to res50imdatagen.h5\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 4707s 6s/step - loss: 1.4281 - acc: 0.5936 - top_5: 0.8633 - top_3: 0.7932 - val_loss: 1.3802 - val_acc: 0.6102 - val_top_5: 0.8684 - val_top_3: 0.8013\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.61009 to 0.61021, saving model to res50imdatagen.h5\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 4765s 6s/step - loss: 1.4257 - acc: 0.5934 - top_5: 0.8636 - top_3: 0.7938 - val_loss: 1.3802 - val_acc: 0.6104 - val_top_5: 0.8684 - val_top_3: 0.8016\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.61021 to 0.61037, saving model to res50imdatagen.h5\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 5920s 7s/step - loss: 1.4226 - acc: 0.5948 - top_5: 0.8643 - top_3: 0.7942 - val_loss: 1.3822 - val_acc: 0.6096 - val_top_5: 0.8686 - val_top_3: 0.8024\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.61037\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 4389s 5s/step - loss: 1.4190 - acc: 0.5953 - top_5: 0.8644 - top_3: 0.7950 - val_loss: 1.3846 - val_acc: 0.6094 - val_top_5: 0.8676 - val_top_3: 0.8006\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.61037\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 4449s 6s/step - loss: 1.4010 - acc: 0.6004 - top_5: 0.8673 - top_3: 0.7983 - val_loss: 1.3681 - val_acc: 0.6131 - val_top_5: 0.8706 - val_top_3: 0.8035\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.61037 to 0.61309, saving model to res50imdatagen.h5\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 4783s 6s/step - loss: 1.3951 - acc: 0.6008 - top_5: 0.8682 - top_3: 0.7996 - val_loss: 1.3714 - val_acc: 0.6124 - val_top_5: 0.8699 - val_top_3: 0.8033\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.61309\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 5080s 6s/step - loss: 1.3937 - acc: 0.6022 - top_5: 0.8689 - top_3: 0.8005 - val_loss: 1.3680 - val_acc: 0.6135 - val_top_5: 0.8703 - val_top_3: 0.8039\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.61309 to 0.61350, saving model to res50imdatagen.h5\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 5431s 7s/step - loss: 1.3901 - acc: 0.6028 - top_5: 0.8694 - top_3: 0.8006 - val_loss: 1.3713 - val_acc: 0.6125 - val_top_5: 0.8697 - val_top_3: 0.8032\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.61350\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 4180s 5s/step - loss: 1.3874 - acc: 0.6035 - top_5: 0.8702 - top_3: 0.8011 - val_loss: 1.3680 - val_acc: 0.6133 - val_top_5: 0.8709 - val_top_3: 0.8035\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.61350\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 4302s 5s/step - loss: 1.3876 - acc: 0.6031 - top_5: 0.8694 - top_3: 0.8009 - val_loss: 1.3679 - val_acc: 0.6138 - val_top_5: 0.8707 - val_top_3: 0.8037\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.61350 to 0.61376, saving model to res50imdatagen.h5\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 4224s 5s/step - loss: 1.3885 - acc: 0.6029 - top_5: 0.8691 - top_3: 0.8007 - val_loss: 1.3672 - val_acc: 0.6136 - val_top_5: 0.8708 - val_top_3: 0.8044\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.61376\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 3994s 5s/step - loss: 1.3873 - acc: 0.6038 - top_5: 0.8695 - top_3: 0.8017 - val_loss: 1.3669 - val_acc: 0.6136 - val_top_5: 0.8711 - val_top_3: 0.8040\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.61376\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 3962s 5s/step - loss: 1.3885 - acc: 0.6025 - top_5: 0.8696 - top_3: 0.8009 - val_loss: 1.3660 - val_acc: 0.6137 - val_top_5: 0.8707 - val_top_3: 0.8041\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.61376\n",
      "Epoch 46/50\n",
      " 72/800 [=>............................] - ETA: 54:57 - loss: 1.3869 - acc: 0.6041 - top_5: 0.8698 - top_3: 0.8006"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, \n",
    "                          validation_data = validation_generator,\n",
    "                    epochs=50, \n",
    "                    steps_per_epoch = len(data_train) // batch_size,\n",
    "                         validation_steps= len(data_test) // batch_size,\n",
    "                    callbacks=[checkpoint, early, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62e99cb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d31fb5d",
   "metadata": {},
   "source": [
    "## Graphique montrant l'évolution de la précision et la perte en fonction des epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd19efb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-86be355d9c9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m121\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('Model loss by epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='right')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.plot(history.history['val_top_5'])\n",
    "plt.plot(history.history['val_top_3'])\n",
    "plt.plot(history.history['val_top_5'])\n",
    "plt.plot(history.history['val_top_3'])\n",
    "plt.title('Model acc by epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1f1609",
   "metadata": {},
   "source": [
    "## Différenciation des deux méthodes utilisées -- Méthode sans ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3e69c4",
   "metadata": {},
   "source": [
    "le modèle est le même mais nous devons efféctué beaucoup plus de travail afin de préparer les données à être entrainées.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fe95f0",
   "metadata": {},
   "source": [
    "# Création d'un array avec la liste des types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58d41b56",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-393532268519>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mCLASS_NAMES\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"genus\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "CLASS_NAMES=np.array(data[\"genus\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f6909af",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CLASS_NAMES' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0ba7baeb02ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mCLASS_NAMES\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'CLASS_NAMES' is not defined"
     ]
    }
   ],
   "source": [
    "CLASS_NAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c56612e",
   "metadata": {},
   "source": [
    "# Découpage du Train Test. Pour pouvoir utilisé Tensorslices, nous ne devont garder qu'une seule colonne. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0abd78c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f5c4e41bab17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"path\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train,test= train_test_split(data[\"path\"],test_size=0.2,random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeaf539",
   "metadata": {},
   "source": [
    "## Définition des fonctions pour mettre en place les données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fee4dc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'types' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-bc58717329e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"genus\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"species\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'types' is not defined"
     ]
    }
   ],
   "source": [
    "if types==\"genus\":\n",
    "    k=-3\n",
    "elif types==\"species\":\n",
    "    k=-2\n",
    "    \n",
    "def parse_image(filename):     #cette fonction à partir du chemin du fichier lit l'image et en extrait aussi le label \n",
    "    parts = tf.strings.split(filename, '\\\\')    #Le label est ici un array de boolén qui a sa valeur True sur l'index qui\n",
    "    label = CLASS_NAMES==parts[k]        #correspond à la position du types trouvé dans CLASS_NAMES\n",
    "    image = tf.io.read_file(filename)   #l'image est aussi décodé de jpeg\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    \n",
    "   \n",
    "    \n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    \n",
    "        \n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36806d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(image):   #Fonction de data augmentation\n",
    "    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    # Flips\n",
    "    if p_spatial >= .2:\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        image = tf.image.random_flip_up_down(image)\n",
    "        \n",
    "    # Rotates\n",
    "    if p_rotate > .75:\n",
    "        image = tf.image.rot90(image, k=3) # rotate 270º\n",
    "    elif p_rotate > .5:\n",
    "        image = tf.image.rot90(image, k=2) # rotate 180º\n",
    "    elif p_rotate > .25:\n",
    "        image = tf.image.rot90(image, k=1) # rotate 90º\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e4ede1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image_train(image, label):   #Fonction augment pour le train\n",
    "    \n",
    "    #image=tf.image.random_flip_left_right(image)\n",
    "    #image=tf.image.random_flip_up_down(image)\n",
    "     \n",
    "    image=augment(image)\n",
    "    image=tf.image.per_image_standardization(image)\n",
    "    image=tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image=tf.keras.applications.nasnet.preprocess_input(image)\n",
    "    #image=tf.image.random_zoom(image, zoom_range=(0.1,0.2),  fill_mode='nearest')\n",
    "    return image, tf.cast(label, tf.float32)     #le label booléen est transformé en array de float "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dcc3e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image_test(image, label):      #idem pour le test\n",
    "    \n",
    "    #image=tf.image.random_flip_left_right(image)\n",
    "    #image=tf.image.random_flip_up_down(image)\n",
    "     \n",
    "    #image=augment(image)\n",
    "    image=tf.image.per_image_standardization(image)\n",
    "    #image=tf.image.random_brightness(image, max_delta=0.1)\n",
    "    #image=tf.image.random_zoom(image, zoom_range=(0.1,0.2),  fill_mode='nearest')\n",
    "    image=tf.keras.applications.nasnet.preprocess_input(image)\n",
    "    return image, tf.cast(label, tf.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6817b0f",
   "metadata": {},
   "source": [
    "## Création des deux pipelines par lequel les deux deux datasets doivent passer pour rentrer dans le modèle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e91d3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_train(file_list,shuffle_buffer_size=1000):       #pipeline pour le train\n",
    "  \n",
    "    ds=tf.data.Dataset.from_tensor_slices(file_list)\n",
    "  \n",
    "    ds=ds.shuffle(buffer_size=len(file_list))\n",
    "\n",
    "    ds=ds.map(parse_image,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    ds=ds.map(augment_image_train,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "  \n",
    "\n",
    "    ds=ds.repeat()\n",
    "\n",
    "    ds=ds.batch(batch_size)\n",
    "\n",
    "    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "  \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c221d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_test(file_list,shuffle_buffer_size=1000):    #pipeline pour le test\n",
    "  \n",
    "    ds=tf.data.Dataset.from_tensor_slices(file_list)\n",
    "  \n",
    "    ds=ds.shuffle(buffer_size=len(file_list))\n",
    "\n",
    "    ds=ds.map(parse_image,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    ds=ds.map(augment_image_test,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "  \n",
    "\n",
    "    ds=ds.repeat()\n",
    "\n",
    "    ds=ds.batch(batch_size)\n",
    "\n",
    "    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "  \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b332b3",
   "metadata": {},
   "source": [
    "## Création des deux datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e859939",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=create_dataset_train(train)                   \n",
    "test_ds=create_dataset_test(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f72330c",
   "metadata": {},
   "source": [
    "## Entrainement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f385ab27",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b20bb6fd8a82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(train_ds,\n\u001b[0m\u001b[0;32m      2\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                          \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,\n",
    "                    epochs=50, \n",
    "                    steps_per_epoch = len(train) // batch_size,\n",
    "                         validation_steps= len(test) // batch_size,\n",
    "                    callbacks=[checkpoint, early, reduce_lr],\n",
    "                    validation_data=test_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b262ed",
   "metadata": {},
   "source": [
    "## Graphique montrant l'évolution de la précision et la perte en fonction des epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "445f9f08",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-1cce9cee5fd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m121\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('Model loss by epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='right')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.plot(history.history['val_top_5'])\n",
    "plt.plot(history.history['val_top_3'])\n",
    "plt.plot(history.history['val_top_5'])\n",
    "plt.plot(history.history['val_top_3'])\n",
    "plt.title('Model acc by epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c529f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
